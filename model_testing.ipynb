{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт"
      ],
      "metadata": {
        "id": "zORm92g8W10a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import keras_nlp\n",
        "from tensorflow import keras\n",
        "from keras import losses, optimizers\n",
        "\n",
        "from urllib.parse import unquote\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "!git clone https://github.com/mitramir55/Kaggle_NLP_competition.git\n",
        "train = pd.read_csv('Kaggle_NLP_competition/train.csv')\n",
        "test = pd.read_csv('Kaggle_NLP_competition/test.csv')\n",
        "\n",
        "\n",
        "# 1. Загрузка TF-IDF векторизатор\n",
        "vectorizer = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/tfidf_vectorizer.joblib\")\n",
        "# 2. Загрузка модели логистической регрессии\n",
        "logreg_model = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/logreg_model.joblib\")\n",
        "\n",
        "# 3. Загрузка модели DistilBERT\n",
        "distilbert_model = keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/saved_model_disaster_tweets.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKTPtipLAWzb",
        "outputId": "f7547b65-b121-493d-9df8-cbf8c6ac7787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Kaggle_NLP_competition'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 81 (delta 0), reused 0 (delta 0), pack-reused 80 (from 1)\u001b[K\n",
            "Receiving objects: 100% (81/81), 11.05 MiB | 15.50 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 210 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mitramir55/Kaggle_NLP_competition.git\n",
        "test_target = pd.read_csv('Kaggle_NLP_competition/perfect_submission.csv')\n",
        "test_target = test_target.drop(['id'],axis=1)\n",
        "test['target'] = test_target['target']\n",
        "test.shape"
      ],
      "metadata": {
        "id": "8Qt0ZxEQ4-jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обработка данных для LogReg"
      ],
      "metadata": {
        "id": "nT5YXawdXiCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_column_for_lr(df):\n",
        "  df = df.copy()\n",
        "\n",
        "  df = df.drop_duplicates(subset='text')\n",
        "  df = df.drop(['id', 'location'], axis=1)\n",
        "  df['keyword'] = df['keyword'].fillna('unknown')\n",
        "  return df\n",
        "\n",
        "# df_train_for_lr = drop_column_for_lr(train)\n",
        "# df_test_for_lr = drop_column_for_lr(test)"
      ],
      "metadata": {
        "id": "elo8V6KwKzpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "# Загрузить модель spaCy English (с отключенным парсером и NER для более высокой производительности)\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
        "\n",
        "def clean_text_spacy(text):\n",
        "    text = text.lower() # Преобразование в нижний регистр\n",
        "    text = re.sub(r\"http\\S+|www\\S+|@\\w+\", \"\", text) # Удаление URL-адресов и упоминаний\n",
        "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text) # Упрошение хэштегов, удалив символ «#».\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text) # Удаление специальных символов и цифр\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip() # Удаление лишних пробелов\n",
        "\n",
        "    # Лемматизировать и удалить стоп-слова, сохранить токены длиннее 2 символов\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and len(token) > 2]\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# df_train_for_lr['cleaned_text'] = df_train_for_lr['text'].apply(clean_text_spacy)\n",
        "# df_test_for_lr['cleaned_text'] = df_test_for_lr['text'].apply(clean_text_spacy)\n",
        "\n",
        "# df_train_for_lr.head()"
      ],
      "metadata": {
        "id": "7C9FR7ZpFAK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import unquote\n",
        "\n",
        "def clear_df_unquote(df):\n",
        "  df['keyword'] = df['keyword'].apply(lambda x: unquote(x.replace('+', ' ')))\n",
        "  df['final_text'] = df['keyword'] + ' ' + df['cleaned_text']\n",
        "  df = df.drop(['keyword', 'text', 'cleaned_text'], axis=1)\n",
        "  df = df[['final_text', 'target']]\n",
        "\n",
        "  return df\n",
        "\n",
        "# df_train_for_lr = clear_df_unquote(df_train_for_lr)\n",
        "# df_test_for_lr = clear_df_unquote(df_test_for_lr)"
      ],
      "metadata": {
        "id": "o3W437Y7K8Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_vectorize_and_split(df, test_size=0.2, random_state=42):\n",
        "  X_for_lr = vectorizer.transform(df['final_text'])\n",
        "  y_for_lr = df['target']\n",
        "  # Разделить данные на обучающие и проверочные наборы\n",
        "  X_train, X_val, y_train, y_val = train_test_split(\n",
        "      X_for_lr, y_for_lr,\n",
        "      test_size=test_size,\n",
        "      stratify=y_for_lr,           # Стратифицированное разделение для сохранения распределения классов\n",
        "      random_state=random_state\n",
        "  )\n",
        "  return X_train, X_val, y_train, y_val\n",
        "\n",
        "# X_train, X_val, y_train, y_val = df_vectorize_and_split(df_train_for_lr)"
      ],
      "metadata": {
        "id": "AsIWl8UqLeFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обработка данных для DistilBert"
      ],
      "metadata": {
        "id": "cq3Y2l_KXKge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_column_for_db(train):\n",
        "  df = train.copy()\n",
        "\n",
        "  df = df.drop_duplicates(subset='text')\n",
        "  df = df.drop(['id', 'location'], axis=1)\n",
        "  df['keyword'] = df['keyword'].fillna('unknown')\n",
        "\n",
        "  df['keyword'] = df['keyword'].apply(lambda x: unquote(x.replace('+', ' ')))\n",
        "\n",
        "  df['final_text'] = df['keyword'] + ' ' + df['text']\n",
        "\n",
        "  df = df.drop(['keyword', 'text'], axis=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "# df_train_for_bert = drop_сolumn_for_db(train)\n",
        "# df_test_for_bert = drop_сolumn_for_db(test)"
      ],
      "metadata": {
        "id": "IqGHmxmr65vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_split(df, test_size=0.2, random_state=42):\n",
        "    X = df['final_text']\n",
        "    y = df['target']\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y,\n",
        "        stratify=y,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n",
        "\n",
        "# X_train, X_val, y_train, y_val = df_split(df_train_for_bert)"
      ],
      "metadata": {
        "id": "3tULalOcCWGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred_prob_by_distilbert = distilbert_model.predict(X_train)"
      ],
      "metadata": {
        "id": "md9JioU5DQsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred_probs_by_distilber = distilbert_model.predict(X_val)"
      ],
      "metadata": {
        "id": "-R4yPaN9lI-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred_by_distilbert = np.argmax(y_train_pred_prob_by_distilbert, axis=1)\n",
        "y_val_pred_by_distilbert = np.argmax(y_val_pred_probs_by_distilber, axis=1)"
      ],
      "metadata": {
        "id": "Ro6qwU5wDoXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Результаты LogRec"
      ],
      "metadata": {
        "id": "bhcW9RAVXpoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_by_lr = logreg_model.predict(X_train)\n",
        "y_pred_val_by_lr = logreg_model.predict(X_val)\n",
        "\n",
        "print(\"Отчет о классификации тренировочного набора:\")\n",
        "print(classification_report(y_train, y_pred_train_by_lr))\n",
        "print(' ')\n",
        "print(\"Отчет о классификации валидационного набора:\")\n",
        "print(classification_report(y_val, y_pred_val_by_lr))"
      ],
      "metadata": {
        "id": "8jv7A_HuL3ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Результаты DisrilBert"
      ],
      "metadata": {
        "id": "xAyML_ztXTT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Отчет о классификации тренировочного набора:\")\n",
        "print(classification_report(y_train, y_train_pred_by_distilbert))\n",
        "print(' ')\n",
        "print(\"Отчет о классификации валидационного набора:\")\n",
        "print(classification_report(y_val, y_val_pred_by_distilbert))"
      ],
      "metadata": {
        "id": "Njqvc0b8DiPZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ансамблирование"
      ],
      "metadata": {
        "id": "iKtUe-gbX7Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_for_lr = drop_column_for_lr(train)\n",
        "train_for_lr['cleaned_text'] = train_for_lr['text'].apply(clean_text_spacy)\n",
        "train_for_lr = clear_df_unquote(train_for_lr)\n",
        "X_train_lr = vectorizer.transform(train_for_lr['final_text'])\n",
        "y_train = train_for_lr['target']\n",
        "\n",
        "train_for_db = drop_сolumn_for_db(train)\n",
        "X_train_db = train_for_db['final_text']\n",
        "\n",
        "test_for_lr = drop_column_for_lr(test)\n",
        "test_for_lr['cleaned_text'] = test_for_lr['text'].apply(clean_text_spacy)\n",
        "test_for_lr = clear_df_unquote(test_for_lr)\n",
        "X_test_lr = vectorizer.transform(test_for_lr['final_text'])\n",
        "y_test = test_for_lr['target']\n",
        "\n",
        "test_for_db = drop_сolumn_for_db(test)\n",
        "X_test_db = test_for_db['final_text']"
      ],
      "metadata": {
        "id": "dTjj7uF9_4KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred_prob_lr = logreg_model.predict_proba(X_train_lr)\n",
        "val_pred_prob_lr = logreg_model.predict_proba(X_test_lr)\n",
        "\n",
        "train_pred_prob_db = distilbert_model.predict(X_train_db)\n",
        "val_pred_prob_db = distilbert_model.predict(X_test_db)\n",
        "\n",
        "# min_val = np.min(y_train_pred_prob_by_distilbert)\n",
        "# max_val = np.max(y_train_pred_prob_by_distilbert)\n",
        "# y_train_pred_prob_by_distilbert_normalized = (y_train_pred_prob_by_distilbert - min_val) / (y_train_pred_prob_by_distilbert - min_val)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "M_57k2GSYHYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, w2 = 0.2, 0.9\n",
        "proba_wa = w1 * val_pred_prob_lr + w2 * val_pred_prob_db\n",
        "preds_wa = proba_wa.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_test, preds_wa))"
      ],
      "metadata": {
        "id": "jm224SIk8guj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_meta_train = np.hstack([\n",
        "    train_pred_prob_lr,\n",
        "    train_pred_prob_db\n",
        "])\n",
        "y_meta_train = y_train.values\n",
        "\n",
        "X_meta_test = np.hstack([\n",
        "    val_pred_prob_lr,\n",
        "    val_pred_prob_db\n",
        "])\n",
        "y_meta_test = y_test.values"
      ],
      "metadata": {
        "id": "yHKQV-u_YJ9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP\n",
        "meta_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(32,16,8),\n",
        "    max_iter=200,\n",
        "    random_state=42)\n",
        "meta_mlp.fit(X_meta_train, y_meta_train)\n",
        "preds_meta = meta_mlp.predict(X_meta_test)\n",
        "\n",
        "\n",
        "print(\"Отчет. Стэкинг, MLPClassifier, валидационный набор:\")\n",
        "print(classification_report(y_meta_test, preds_meta))"
      ],
      "metadata": {
        "id": "1jMmbIokoGqa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# XGBoost\n",
        "meta_xgb = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.001,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "meta_xgb.fit(X_meta_train, y_meta_train)\n",
        "\n",
        "preds_xgb = meta_xgb.predict(X_meta_test)\n",
        "print(\"Stacking XGBoost Report:\")\n",
        "print(classification_report(y_meta_test, preds_xgb))"
      ],
      "metadata": {
        "id": "NtqR7g1N-zXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# RandomForest\n",
        "meta_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "meta_rf.fit(X_meta_train, y_meta_train)\n",
        "\n",
        "preds_rf = meta_rf.predict(X_meta_test)\n",
        "print(\"Stacking RandomForest Report:\")\n",
        "print(classification_report(y_meta_test, preds_rf))"
      ],
      "metadata": {
        "id": "6mgqBL-5-1ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функции тестирования"
      ],
      "metadata": {
        "id": "_m1zUZfVA3wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "own_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/own_dataset.csv')"
      ],
      "metadata": {
        "id": "4Moo-YoNSts7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_predictions(results_df, n_samples=2):\n",
        "    print(\"\\nОтчет о классификации:\")\n",
        "    print(classification_report(\n",
        "        results_df['true_label'],\n",
        "        results_df['predicted_label']))\n",
        "\n",
        "    fp = results_df[(results_df['true_label'] == 0) & (results_df['predicted_label'] == 1)]\n",
        "    fn = results_df[(results_df['true_label'] == 1) & (results_df['predicted_label'] == 0)]\n",
        "    tp = results_df[(results_df['true_label'] == 1) & (results_df['predicted_label'] == 1)]\n",
        "    tn = results_df[(results_df['true_label'] == 0) & (results_df['predicted_label'] == 0)]\n",
        "\n",
        "    def print_samples(category, samples):\n",
        "        print(f\"\\n{category} ({len(samples)} всего):\")\n",
        "        if len(samples) > 0:\n",
        "            for i, row in samples.sample(min(n_samples, len(samples))).iterrows():\n",
        "                print(f\"Сообщение({i}):\")\n",
        "                print(f\"\\tТекст сообщения: {row['original_text']}\")\n",
        "                if row['true_label'] == 1:\n",
        "                    print(\"\\tИстинный: катастрофа\")\n",
        "                else:\n",
        "                    print(\"\\tИстинный: не катастрофа\")\n",
        "\n",
        "                if row['predicted_label'] == 1:\n",
        "                    print(\"\\tПредсказанный: катастрофа\")\n",
        "                else:\n",
        "                    print(\"\\tПредсказанный: не катастрофа\")\n",
        "        else:\n",
        "            print(\"Нет примеров\")\n",
        "\n",
        "    print_samples(\"Ложноположительные\", fp)\n",
        "    print_samples(\"Ложноотрицательные\", fn)\n",
        "    print_samples(\"Истинноположительные\", tp)\n",
        "    print_samples(\"Истинноотрицательные\", tn)"
      ],
      "metadata": {
        "id": "MRE8M8Xh_K3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text_by_lr(df):\n",
        "    if isinstance(df, str):\n",
        "        cleaned_tweet = clean_text_spacy(df)\n",
        "        vectorized_tweet = vectorizer.transform([cleaned_tweet])\n",
        "        logrec_pred = logreg_model.predict(vectorized_tweet)\n",
        "        if logrec_pred == 0:\n",
        "          print(\"Логическая регрессия предсказала что это: не катастрофа\")\n",
        "        elif logrec_pred == 1:\n",
        "          print(\"Логическая регрессия предсказала что это: катастрофа\")\n",
        "        print(\"При вероятностях:\", logreg_model.predict_proba(vectorized_tweet))"
      ],
      "metadata": {
        "id": "taZ4XTtIms80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text_by_db(df):\n",
        "    if isinstance(df, str):\n",
        "        distilbert_logit = distilbert_model.predict([df])\n",
        "        distilbert_pred = distilbert_logit.argmax(axis=-1)\n",
        "        if distilbert_pred == 0:\n",
        "          print(\"DistilBERT предсказал что это: не катастрофа\")\n",
        "        elif distilbert_pred == 1:\n",
        "          print(\"DistilBERT предсказал что это: катастрофа\")\n",
        "        print(\"С вероятностями: \", distilbert_logit)"
      ],
      "metadata": {
        "id": "Qv_8FXmjdikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_df_by_lr(df):\n",
        "    df_for_lr = drop_column_for_lr(df)\n",
        "    df_for_lr['cleaned_text'] = df_for_lr['text'].apply(clean_text_spacy)\n",
        "    df_for_lr = clear_df_unquote(df_for_lr)\n",
        "\n",
        "    X = vectorizer.transform(df_for_lr['final_text'])\n",
        "    y = df_for_lr['target'].values\n",
        "\n",
        "    pred_by_lr = logreg_model.predict(X)\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        'original_text': df['text'],\n",
        "        'true_label': y,\n",
        "        'predicted_label': pred_by_lr\n",
        "    })\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "id1br5L69nJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_df_by_db(df):\n",
        "    df_for_bert = drop_column_for_db(df)\n",
        "\n",
        "    X = df_for_bert['final_text']\n",
        "    y = df_for_bert['target']\n",
        "\n",
        "    pred_prob_by_distilbert = distilbert_model.predict(X)\n",
        "    pred_by_distilbert = np.argmax(pred_prob_by_distilbert, axis=1)\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        'original_text': X,\n",
        "        'true_label': y,\n",
        "        'predicted_label': pred_by_distilbert\n",
        "        })\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "1p2TtzJr_aVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_lr = predict_df_by_lr(own_df)\n",
        "analyze_predictions(results_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aDnjAHXe_Ntd",
        "outputId": "f10769f1-b3cc-4c5d-9d27-21f32b53c2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.79      0.71        14\n",
            "           1       0.80      0.67      0.73        18\n",
            "\n",
            "    accuracy                           0.72        32\n",
            "   macro avg       0.72      0.73      0.72        32\n",
            "weighted avg       0.73      0.72      0.72        32\n",
            "\n",
            "\n",
            "Ложноположительные (3 всего):\n",
            "Сообщение(27):\n",
            "\tТекст сообщения: Festive namaz at the Moscow Cathedral Mosque near Prospekt Mira on the occasion of Eid al-Adha\n",
            "\tИстинный: не катастрофа\n",
            "\tПредсказанный: катастрофа\n",
            "Сообщение(30):\n",
            "\tТекст сообщения: A fat trained pig surprised Muscovites. A grunting mini-caban from Southern Butovo has delighted passers.\n",
            "\tИстинный: не катастрофа\n",
            "\tПредсказанный: катастрофа\n",
            "\n",
            "Ложноотрицательные (6 всего):\n",
            "Сообщение(8):\n",
            "\tТекст сообщения: The first summer thunderstorm came to Moscow - lightning struck the Ostankino TV Tower\n",
            "\tИстинный: катастрофа\n",
            "\tПредсказанный: не катастрофа\n",
            "Сообщение(1):\n",
            "\tТекст сообщения: Smoke occurred at the coke plant in Kryvyi Rih, the city was covered with smog\n",
            "\tИстинный: катастрофа\n",
            "\tПредсказанный: не катастрофа\n",
            "\n",
            "Истинноположительные (12 всего):\n",
            "Сообщение(26):\n",
            "\tТекст сообщения: Tropical showers with thunderstorms will hit Moscow as early as today\n",
            "\tИстинный: катастрофа\n",
            "\tПредсказанный: катастрофа\n",
            "Сообщение(2):\n",
            "\tТекст сообщения: A civilian was killed and 3 others wounded in the town of Graivoron, Belgorod Region, after an AFU strike\n",
            "\tИстинный: катастрофа\n",
            "\tПредсказанный: катастрофа\n",
            "\n",
            "Истинноотрицательные (11 всего):\n",
            "Сообщение(31):\n",
            "\tТекст сообщения: Armenian PM Pashinyan congratulates Azerbaijan on Eid al-Adha for the first time\n",
            "\tИстинный: не катастрофа\n",
            "\tПредсказанный: не катастрофа\n",
            "Сообщение(15):\n",
            "\tТекст сообщения: CSKA and AEK may swap head coaches: Argentine Matias Almeida is one of the main favorites to become CSKA coach\n",
            "\tИстинный: не катастрофа\n",
            "\tПредсказанный: не катастрофа\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_db = predict_df_by_db(own_df)\n",
        "analyze_predictions(results_db)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp7-S3R3A46B",
        "outputId": "4a708c3a-a071-41a3-f809-c045a182693f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936ms/step\n",
            "\n",
            "Отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.79      0.88        14\n",
            "           1       0.86      1.00      0.92        18\n",
            "\n",
            "    accuracy                           0.91        32\n",
            "   macro avg       0.93      0.89      0.90        32\n",
            "weighted avg       0.92      0.91      0.90        32\n",
            "\n",
            "\n",
            "Ложноположительные (3 всего):\n",
            "Сообщение(3):\n",
            "\tТекст сообщения: unknown The situation with coronavirus in Russia is stable and controlled, there is no information about the emergence of a new virus\n",
            "\tИстинный: не катастрофа\n",
            "\tПредсказанный: катастрофа\n",
            "Сообщение(10):\n",
            "\tТекст сообщения: unknown The coming week in the Moscow region is expected to be much colder than the outgoing one, with average temperatures 1-2 degrees below normal\n",
            "\tИстинный: не катастрофа\n",
            "\tПредсказанный: катастрофа\n",
            "\n",
            "Ложноотрицательные (0 всего):\n",
            "Нет примеров\n",
            "\n",
            "Истинноположительные (18 всего):\n",
            "Сообщение(11):\n",
            "\tТекст сообщения: unknown Rocket danger declared in Crimea for the fourth time in a day\n",
            "\tИстинный: катастрофа\n",
            "\tПредсказанный: катастрофа\n",
            "Сообщение(25):\n",
            "\tТекст сообщения: unknown Muscovite fell through a hole in the entryway\n",
            "\tИстинный: катастрофа\n",
            "\tПредсказанный: катастрофа\n",
            "\n",
            "Истинноотрицательные (11 всего):\n",
            "Сообщение(13):\n",
            "\tТекст сообщения: unknown Tomorrow Russians start a short working week - only 3 days\n",
            "\tИстинный: не катастрофа\n",
            "\tПредсказанный: не катастрофа\n",
            "Сообщение(27):\n",
            "\tТекст сообщения: unknown Festive namaz at the Moscow Cathedral Mosque near Prospekt Mira on the occasion of Eid al-Adha\n",
            "\tИстинный: не катастрофа\n",
            "\tПредсказанный: не катастрофа\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"An unidentified man with a hammer and stones attacked a synagogue in Sochi, filming everything on his phone\"\n",
        "\n",
        "predict_text_by_db(text)\n",
        "print('')\n",
        "predict_text_by_lr(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFIcIDFIRrzk",
        "outputId": "64ead279-3517-44f3-a8c4-3a04b8e5c9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step\n",
            "DistilBERT предсказал что это: катастрофа\n",
            "С вероятностями:  [[-1.063919   1.0191315]]\n",
            "\n",
            "Логическая регрессия предсказала что это: не катастрофа\n",
            "При вероятностях: [[0.68480423 0.31519577]]\n"
          ]
        }
      ]
    }
  ]
}